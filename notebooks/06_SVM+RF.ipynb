{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tslearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "sys.path.append(\"../src/models\")\n",
    "import sklearn\n",
    "import tslearn\n",
    "import argparse\n",
    "from train import prepare_dataset\n",
    "from experiments import experiments\n",
    "import tqdm\n",
    "import numpy as np\n",
    "from tslearn.svm import TimeSeriesSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import classification_report\n",
    "from utils.classmetric import confusion_matrix_to_accuraccies\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from tslearn.utils import to_time_series_dataset\n",
    "from time import time\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import scipy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from utils.data2numpy import get_data\n",
    "\n",
    "from fastai_timeseries import *\n",
    "\n",
    "def flatten(x):\n",
    "    return x.reshape(x.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.dataroot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_per_class = 500\n",
    "\n",
    "#tum_ds = get_data(\"isprs_rf_tum_23classes\", dataroot='/home/glennmoncrieff/crop-type-mapping',N_per_class=N_per_class, N_largest=None, do_add_spectral_indices=True)\n",
    "#gaf_ds = get_data(\"isprs_rf_gaf_23classes\", N_per_class=N_per_class, N_largest=None, do_add_spectral_indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 37/10242 [00:00<00:28, 360.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing BavarianCropsDataset test partition in holl\n",
      "read 12 classes\n",
      "no cached dataset found. iterating through csv folders in /home/glennmoncrieff/crop-type-mapping/notebooks/data/BavarianCrops/csv/holl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10242/10242 [00:27<00:00, 379.25it/s]\n",
      "  0%|          | 17/3664 [00:00<00:21, 166.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 9583 samples\n",
      "Dataset /home/glennmoncrieff/crop-type-mapping/notebooks/data/BavarianCrops. region holl. partition test. X:9583x(144, 13), y:(9583,) with 12 classes\n",
      "Initializing BavarianCropsDataset test partition in nowa\n",
      "read 12 classes\n",
      "no cached dataset found. iterating through csv folders in /home/glennmoncrieff/crop-type-mapping/notebooks/data/BavarianCrops/csv/nowa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3664/3664 [00:21<00:00, 172.70it/s]\n",
      "  1%|          | 47/4492 [00:00<00:09, 465.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 3547 samples\n",
      "Dataset /home/glennmoncrieff/crop-type-mapping/notebooks/data/BavarianCrops. region nowa. partition test. X:3547x(287, 13), y:(3547,) with 12 classes\n",
      "Initializing BavarianCropsDataset test partition in krum\n",
      "read 12 classes\n",
      "no cached dataset found. iterating through csv folders in /home/glennmoncrieff/crop-type-mapping/notebooks/data/BavarianCrops/csv/krum\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4492/4492 [00:10<00:00, 439.10it/s]\n",
      "  0%|          | 45/26618 [00:00<01:00, 438.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 4278 samples\n",
      "Dataset /home/glennmoncrieff/crop-type-mapping/notebooks/data/BavarianCrops. region krum. partition test. X:4278x(143, 13), y:(4278,) with 12 classes\n",
      "Initializing BavarianCropsDataset trainvalid partition in holl\n",
      "read 12 classes\n",
      "no cached dataset found. iterating through csv folders in /home/glennmoncrieff/crop-type-mapping/notebooks/data/BavarianCrops/csv/holl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26618/26618 [00:59<00:00, 448.19it/s]\n",
      "  0%|          | 22/8635 [00:00<00:40, 213.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 24767 samples\n",
      "Dataset /home/glennmoncrieff/crop-type-mapping/notebooks/data/BavarianCrops. region holl. partition trainvalid. X:24767x(71, 13), y:(24767,) with 12 classes\n",
      "Initializing BavarianCropsDataset trainvalid partition in nowa\n",
      "read 12 classes\n",
      "no cached dataset found. iterating through csv folders in /home/glennmoncrieff/crop-type-mapping/notebooks/data/BavarianCrops/csv/nowa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8635/8635 [00:45<00:00, 188.89it/s]\n",
      "  0%|          | 53/26064 [00:00<00:49, 527.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 8425 samples\n",
      "Dataset /home/glennmoncrieff/crop-type-mapping/notebooks/data/BavarianCrops. region nowa. partition trainvalid. X:8425x(289, 13), y:(8425,) with 12 classes\n",
      "Initializing BavarianCropsDataset trainvalid partition in krum\n",
      "read 12 classes\n",
      "no cached dataset found. iterating through csv folders in /home/glennmoncrieff/crop-type-mapping/notebooks/data/BavarianCrops/csv/krum\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26064/26064 [00:56<00:00, 461.18it/s]\n",
      "3it [00:00, 27.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 25083 samples\n",
      "Dataset /home/glennmoncrieff/crop-type-mapping/notebooks/data/BavarianCrops. region krum. partition trainvalid. X:25083x(71, 13), y:(25083,) with 12 classes\n",
      "setting random seed to 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "228it [00:07, 29.29it/s]\n",
      "68it [00:02, 30.41it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tum12_ds = get_data(\"isprs_rf_tum_12classes\", N_per_class=N_per_class, N_largest=None, do_add_spectral_indices=True)\n",
    "#gaf12_ds = get_data(\"isprs_rf_gaf_12classes\", dataroot=os.getcwd(),N_per_class=N_per_class, N_largest=None, do_add_spectral_indices=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TUM dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!cat /data/isprs/sklearn/svm_tum.txt\n",
    "#svm_tum_params = {'C': 34.94762791972138, 'gamma': 0.09632187442535493, 'kernel': 'rbf'}\n",
    "#svm_tum_params ={'C': 219.5746177088989, 'gamma': 0.030512293944411368, 'kernel': 'rbf'}\n",
    "svm_tum_params ={'C': 219.5746177088989, 'gamma': 0.030512293944411368, 'kernel': 'rbf'}\n",
    "!cat /data/isprs/sklearn/svm_gaf.txt\n",
    "svm_gaf_params = {'C': 83.60975452306279, 'gamma': 0.03084148398718425, 'kernel': 'rbf'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y,ids, Xtest, ytest, idstest, classnames, class_idxs = tum_ds\n",
    "\n",
    "clf = TimeSeriesSVC(n_jobs=8,**svm_tum_params)\n",
    "clf.fit(X, y)\n",
    "y_pred = clf.predict(Xtest)\n",
    "print(classification_report(ytest, y_pred,labels=class_idxs, target_names=classnames))\n",
    "metrics = confusion_matrix_to_accuraccies(confusion_matrix(ytest,y_pred))\n",
    "overall_accuracy, kappa, precision, recall, f1, cl_acc = metrics\n",
    "print(f\"overall accuracy = {overall_accuracy:.2f}, kappa = {kappa:.2f}, precision = {precision.mean():.2f},\",\n",
    "      f\"recall={recall.mean():.2f}, f1={f1.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y,ids, Xtest, ytest, idstest, classnames, class_idxs = gaf_ds\n",
    "\n",
    "clf = sklearn.svm.SVC(**svm_tum_params)\n",
    "#clf = TimeSerxiesSVC(n_jobs=8,**svm_tum_params)\n",
    "clf.fit(feat_ext(X), y)\n",
    "y_pred = clf.predict(feat_ext(Xtest))\n",
    "print(classification_report(ytest, y_pred,labels=class_idxs, target_names=classnames))\n",
    "metrics = confusion_matrix_to_accuraccies(confusion_matrix(ytest,y_pred))\n",
    "overall_accuracy, kappa, precision, recall, f1, cl_acc = metrics\n",
    "print(f\"overall accuracy = {overall_accuracy:.2f}, kappa = {kappa:.2f}, precision = {precision.mean():.2f},\",\n",
    "      f\"recall={recall.mean():.2f}, f1={f1.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tsfresh\n",
    "from tsfresh import extract_features\n",
    "extracted_features = extract_features(X[0,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_ext(X):\n",
    "    f1 = X.mean(1)\n",
    "    f2 = X.std(1)\n",
    "    f3 = np.median(X,1)\n",
    "    return np.hstack([f1,f2,f2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAF Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y,ids, Xtest, ytest, idstest, classnames, class_idxs = gaf_ds\n",
    "\n",
    "clf = TimeSeriesSVC(n_jobs=8,**svm_gaf_params)\n",
    "clf.fit(X, y)\n",
    "y_pred = clf.predict(Xtest)\n",
    "print(classification_report(ytest, y_pred,labels=class_idxs, target_names=classnames))\n",
    "metrics = confusion_matrix_to_accuraccies(confusion_matrix(ytest,y_pred))\n",
    "overall_accuracy, kappa, precision, recall, f1, cl_acc = metrics\n",
    "print(f\"overall accuracy = {overall_accuracy:.2f}, kappa = {kappa:.2f}, precision = {precision.mean():.2f},\",\n",
    "      f\"recall={recall.mean():.2f}, f1={f1.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest and Rocket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "params = {'n_estimators': 1400, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth': 70, 'bootstrap': False}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: /data/isprs/sklearn/random_forest_tum.txt: No such file or directory\n",
      "cat: /data/isprs/sklearn/random_forest_gaf.txt: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!cat /data/isprs/sklearn/random_forest_tum.txt\n",
    "rf_tum_params = {'bootstrap': False, 'max_depth': 70, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 2000}\n",
    "#rf_tum_params = {'bootstrap': False, 'max_depth': 50, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 2000}\n",
    "!cat /data/isprs/sklearn/random_forest_gaf.txt\n",
    "rf_gaf_params = {'bootstrap': False, 'max_depth': 60, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 1000}\n",
    "#rf_gaf_params = {'bootstrap': False, 'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 1200}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rocket setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch: 1.3.0\n",
      "fastai : 1.0.59\n"
     ]
    }
   ],
   "source": [
    "from fastai_timeseries import *\n",
    "print('pytorch:', torch.__version__)\n",
    "print('fastai :', fastai.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ROCKET(nn.Module):\n",
    "    def __init__(self, c_in, seq_len, n_kernels=10000, kss=[7, 9, 11]):\n",
    "        \n",
    "        '''\n",
    "        ROCKET is a GPU Pytorch implementation of the ROCKET methods generate_kernels \n",
    "        and apply_kernels that can be used  with univariate and multivariate time series.\n",
    "        Input: is a 3d torch tensor of type torch.float32. When used with univariate TS, \n",
    "        make sure you transform the 2d to 3d by adding unsqueeze(1).\n",
    "        c_in: number of channels or features. For univariate c_in is 1.\n",
    "        seq_len: sequence length\n",
    "        '''\n",
    "        super().__init__()\n",
    "        kss = [ks for ks in kss if ks < seq_len]\n",
    "        convs = nn.ModuleList()\n",
    "        for i in range(n_kernels):\n",
    "            ks = np.random.choice(kss)\n",
    "            dilation = 2**np.random.uniform(0, np.log2((seq_len - 1) // (ks - 1)))\n",
    "            padding = int((ks - 1) * dilation // 2) if np.random.randint(2) == 1 else 0\n",
    "            weight = torch.randn(1, c_in, ks)\n",
    "            weight -= weight.mean()\n",
    "            bias = 2 * (torch.rand(1) - .5)\n",
    "            layer = nn.Conv1d(c_in, 1, ks, padding=2 * padding, dilation=int(dilation), bias=True)\n",
    "            layer.weight = torch.nn.Parameter(weight, requires_grad=False)\n",
    "            layer.bias = torch.nn.Parameter(bias, requires_grad=False)\n",
    "            convs.append(layer)\n",
    "        self.convs = convs\n",
    "        self.n_kernels = n_kernels\n",
    "        self.kss = kss\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(self.n_kernels):\n",
    "            out = self.convs[i](x)\n",
    "            _max = out.max(dim=-1).values\n",
    "            _ppv = torch.gt(out, 0).sum(dim=-1).float() / out.shape[-1]\n",
    "            cat = torch.cat((_max, _ppv), dim=-1)\n",
    "            output = cat if i == 0 else torch.cat((output, cat), dim=-1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rocket eg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 10, 400)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train, X_valid, y_valid = get_UCR_data('HandMovementDirection')\n",
    "X_train.shape\n",
    "\n",
    "_, features, seq_len = X_train.shape\n",
    "X_train = (X_train - X_train.mean(axis=(1, 2), keepdims=True)) / (\n",
    "    X_train.std(axis=(1, 2), keepdims=True) + 1e-8)\n",
    "X_valid = (X_valid - X_valid.mean(axis=(1, 2), keepdims=True)) / (\n",
    "    X_valid.std(axis=(1, 2), keepdims=True) + 1e-8)\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32, device=device)\n",
    "X_valid = torch.tensor(X_valid, dtype=torch.float32, device=device)\n",
    "print(X_train.shape, X_valid.shape, y_train.shape, y_valid.shape)\n",
    "\n",
    "n_kernels=100\n",
    "kss=[7, 9, 11]\n",
    "model = ROCKET(features, seq_len, n_kernels=n_kernels, kss=kss).to(device)\n",
    "\n",
    "X_train_tfm = model(X_train)\n",
    "X_valid_tfm = model(X_valid)\n",
    "\n",
    "X_train_tfm.shape\n",
    "\n",
    "\n",
    "ridge = RidgeClassifierCV(alphas=np.logspace(-8, 8, 17), normalize=True)\n",
    "ridge.fit(X_train_tfm, y_train)\n",
    "\n",
    "rf_tum = RandomForestClassifier(n_jobs=-1,**rf_tum_params)\n",
    "rf_tum.fit(flatten(X),y)\n",
    "y_pred = rf_tum.predict(flatten(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Dataset 23 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y,ids, Xtest, ytest, idstest, classnames, class_idxs = tum_ds\n",
    "\n",
    "rf_tum = RandomForestClassifier(n_jobs=-1,**rf_tum_params)\n",
    "rf_tum.fit(flatten(X),y)\n",
    "y_pred = rf_tum.predict(flatten(Xtest))\n",
    "print(classification_report(ytest, y_pred,labels=class_idxs, target_names=classnames))\n",
    "metrics = confusion_matrix_to_accuraccies(confusion_matrix(ytest,y_pred))\n",
    "overall_accuracy, kappa, precision, recall, f1, cl_acc = metrics\n",
    "print(f\"overall accuracy = {overall_accuracy:.2f}, kappa = {kappa:.2f}, precision = {precision.mean():.2f},\",\n",
    "      f\"recall={recall.mean():.2f}, f1={f1.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "                     precision    recall  f1-score   support\n",
    "\n",
    "             fallow       0.23      0.15      0.19       356\n",
    "      fallow+flower       0.29      0.30      0.29       225\n",
    "            alfalfa       0.50      0.14      0.22       500\n",
    "          grassland       0.31      0.13      0.19       469\n",
    "      proteinplants       0.00      0.00      0.00        23\n",
    "       winter wheat       0.38      0.18      0.24       500\n",
    "               corn       0.72      0.72      0.72       500\n",
    "       summer wheat       0.00      0.00      0.00        56\n",
    "           beetroot       1.00      0.06      0.12        16\n",
    "            potatoe       0.09      0.22      0.12       121\n",
    "grassland+machining       0.29      0.34      0.32       500\n",
    "   grassland+cattle       0.15      0.29      0.19       226\n",
    "       winter spelt       1.00      0.02      0.04        52\n",
    "         winter rye       0.33      0.01      0.02       104\n",
    "      winter barley       0.49      0.26      0.34       500\n",
    "      summer barley       0.49      0.50      0.50       500\n",
    "         summer oat       0.20      0.48      0.28       248\n",
    "   winter triticale       0.21      0.53      0.30       466\n",
    "               peas       0.29      0.16      0.20        90\n",
    "              beans       0.00      0.00      0.00        12\n",
    "           rapeseed       0.67      0.70      0.69       257\n",
    "         summeroats       0.00      0.00      0.00        27\n",
    "    wintertriticale       0.00      0.00      0.00        33\n",
    "\n",
    "           accuracy                           0.33      5781\n",
    "          macro avg       0.33      0.23      0.22      5781\n",
    "       weighted avg       0.38      0.33      0.32      5781\n",
    "\n",
    "overall accuracy = 0.33, kappa = 0.28, precision = 0.33, recall=0.23, f1=0.22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessed Dataset 23 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y,ids, Xtest, ytest, idstest, classnames, class_idxs = gaf_ds\n",
    "\n",
    "rf_tum = RandomForestClassifier(n_jobs=-1,**rf_gaf_params)\n",
    "rf_tum.fit(flatten(X),y)\n",
    "y_pred = rf_tum.predict(flatten(Xtest))\n",
    "print(classification_report(ytest, y_pred,labels=class_idxs, target_names=classnames))\n",
    "metrics = confusion_matrix_to_accuraccies(confusion_matrix(ytest,y_pred))\n",
    "overall_accuracy, kappa, precision, recall, f1, cl_acc = metrics\n",
    "print(f\"overall accuracy = {overall_accuracy:.2f}, kappa = {kappa:.2f}, precision = {precision.mean():.2f},\",\n",
    "      f\"recall={recall.mean():.2f}, f1={f1.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "     precision    recall  f1-score   support\n",
    "\n",
    "             fallow       0.31      0.35      0.33       136\n",
    "      fallow+flower       0.69      0.75      0.72       159\n",
    "            alfalfa       0.63      0.41      0.49       500\n",
    "          grassland       0.33      0.31      0.32       314\n",
    "      proteinplants       0.00      0.00      0.00        21\n",
    "       winter wheat       0.63      0.52      0.57       500\n",
    "               corn       0.99      0.98      0.98       500\n",
    "       summer wheat       1.00      0.12      0.22        33\n",
    "           beetroot       1.00      0.30      0.46        10\n",
    "            potatoe       0.20      0.40      0.27         5\n",
    "grassland+machining       0.53      0.42      0.47       500\n",
    "   grassland+cattle       0.24      0.66      0.35       153\n",
    "       winter spelt       0.60      0.15      0.24        41\n",
    "         winter rye       0.58      0.11      0.19        97\n",
    "      winter barley       0.82      0.71      0.76       500\n",
    "      summer barley       0.75      0.86      0.80       500\n",
    "         summer oat       0.52      0.79      0.63       196\n",
    "   winter triticale       0.45      0.63      0.53       412\n",
    "               peas       0.64      0.72      0.68        76\n",
    "              beans       1.00      0.50      0.67        10\n",
    "           rapeseed       0.91      0.92      0.92       248\n",
    "         summeroats       0.00      0.00      0.00        24\n",
    "    wintertriticale       0.53      0.32      0.40        28\n",
    "\n",
    "           accuracy                           0.61      4963\n",
    "          macro avg       0.58      0.48      0.48      4963\n",
    "       weighted avg       0.64      0.61      0.61      4963\n",
    "\n",
    "overall accuracy = 0.61, kappa = 0.58, precision = 0.58, recall=0.48, f1=0.48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## raw Dataset 12 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y,ids, Xtest, ytest, idstest, classnames, class_idxs = tum12_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Rocket + RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "obsx,tsx,bax = Xtest.shape\n",
    "obs,ts,ba = X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_r= X.reshape(obs,ba,ts)\n",
    "Xtest_r= Xtest.reshape(obsx,bax,tsx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, features, seq_len = X_r.shape\n",
    "X_t = torch.tensor(X_r, dtype=torch.float32, device=device)\n",
    "X_p = torch.tensor(Xtest_r, dtype=torch.float32, device=device)\n",
    "n_kernels=1000\n",
    "kss=[5,10,20,40,70]\n",
    "model = ROCKET(features, seq_len, n_kernels=n_kernels, kss=kss).to(device)\n",
    "X_tfm = model(X_t)\n",
    "Xp_tfm = model(X_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4987, 2000])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tfm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_tum = RandomForestClassifier(n_jobs=-1,**rf_tum_params)\n",
    "rf_tum.fit(X_tfm,y)\n",
    "y_pred = rf_tum.predict(Xp_tfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "          fallow       0.33      0.27      0.30       500\n",
      "       grassland       0.45      0.34      0.39       500\n",
      "    winter wheat       0.02      0.00      0.01       500\n",
      "            corn       0.49      0.38      0.43       500\n",
      "    summer wheat       0.00      0.00      0.00        56\n",
      "    winter spelt       0.00      0.00      0.00        52\n",
      "      winter rye       0.00      0.00      0.00       104\n",
      "   winter barley       0.19      0.03      0.05       500\n",
      "   summer barley       0.29      0.44      0.35       500\n",
      "      summer oat       0.21      0.39      0.28       275\n",
      "winter triticale       0.16      0.37      0.22       499\n",
      "        rapeseed       0.24      0.42      0.31       257\n",
      "\n",
      "        accuracy                           0.27      4243\n",
      "       macro avg       0.20      0.22      0.19      4243\n",
      "    weighted avg       0.26      0.27      0.24      4243\n",
      "\n",
      "overall accuracy = 0.27, kappa = 0.18, precision = 0.20, recall=0.22, f1=0.19\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest, y_pred,labels=class_idxs, target_names=classnames))\n",
    "metrics = confusion_matrix_to_accuraccies(confusion_matrix(ytest,y_pred))\n",
    "overall_accuracy, kappa, precision, recall, f1, cl_acc = metrics\n",
    "print(f\"overall accuracy = {overall_accuracy:.2f}, kappa = {kappa:.2f}, precision = {precision.mean():.2f},\",\n",
    "      f\"recall={recall.mean():.2f}, f1={f1.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Only RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "          fallow       0.55      0.39      0.46       500\n",
      "       grassland       0.64      0.57      0.60       500\n",
      "    winter wheat       0.42      0.22      0.29       500\n",
      "            corn       0.81      0.79      0.80       500\n",
      "    summer wheat       0.00      0.00      0.00        56\n",
      "    winter spelt       0.67      0.04      0.07        52\n",
      "      winter rye       0.23      0.03      0.05       104\n",
      "   winter barley       0.52      0.26      0.35       500\n",
      "   summer barley       0.53      0.47      0.50       500\n",
      "      summer oat       0.25      0.59      0.35       275\n",
      "winter triticale       0.25      0.54      0.34       499\n",
      "        rapeseed       0.80      0.72      0.76       257\n",
      "\n",
      "        accuracy                           0.47      4243\n",
      "       macro avg       0.47      0.39      0.38      4243\n",
      "    weighted avg       0.52      0.47      0.46      4243\n",
      "\n",
      "overall accuracy = 0.47, kappa = 0.40, precision = 0.47, recall=0.39, f1=0.38\n"
     ]
    }
   ],
   "source": [
    "rf_tum = RandomForestClassifier(n_jobs=-1,**rf_tum_params)\n",
    "rf_tum.fit(flatten(X),y)\n",
    "y_pred = rf_tum.predict(flatten(Xtest))\n",
    "print(classification_report(ytest, y_pred,labels=class_idxs, target_names=classnames))\n",
    "metrics = confusion_matrix_to_accuraccies(confusion_matrix(ytest,y_pred))\n",
    "overall_accuracy, kappa, precision, recall, f1, cl_acc = metrics\n",
    "print(f\"overall accuracy = {overall_accuracy:.2f}, kappa = {kappa:.2f}, precision = {precision.mean():.2f},\",\n",
    "      f\"recall={recall.mean():.2f}, f1={f1.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pre Dataset 12 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y,ids, Xtest, ytest, idstest, classnames, class_idxs = gaf12_ds\n",
    "\n",
    "rf_tum = RandomForestClassifier(n_jobs=-1,**rf_tum_params)\n",
    "rf_tum.fit(flatten(X),y)\n",
    "y_pred = rf_tum.predict(flatten(Xtest))\n",
    "print(classification_report(ytest, y_pred,labels=class_idxs, target_names=classnames))\n",
    "metrics = confusion_matrix_to_accuraccies(confusion_matrix(ytest,y_pred))\n",
    "overall_accuracy, kappa, precision, recall, f1, cl_acc = metrics\n",
    "print(f\"overall accuracy = {overall_accuracy:.2f}, kappa = {kappa:.2f}, precision = {precision.mean():.2f},\",\n",
    "      f\"recall={recall.mean():.2f}, f1={f1.mean():.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-crop-type-mapping] *",
   "language": "python",
   "name": "conda-env-.conda-crop-type-mapping-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
